# site.py
import streamlit as st
import requests
import pandas as pd
import xml.etree.ElementTree as ET
from urllib.parse import quote

st.set_page_config(page_title="ì§ì¥ ë‚´ ì¸ì‹ê°œì„  êµìœ¡ ì½˜í…ì¸  í˜„í™©", layout="wide")

st.title("ğŸ¢ ì§ì¥ ë‚´ ì¸ì‹ê°œì„  êµìœ¡ ì½˜í…ì¸  í˜„í™©")

# 1ï¸âƒ£ ì‚¬ìš©ì ì„¤ì •
service_key = "5b4b3917e3b9a6a48763aa2cd0ca266d6ee935d8be01ab9728fb2b77a7f67935"
service_key_encoded = quote(service_key)  # ì¸ì¦í‚¤ URL ì¸ì½”ë”©

page_no = 1
num_of_rows = 100
response_type = "xml"

# 2ï¸âƒ£ API ìš”ì²­ URL
url = f"https://apis.data.go.kr/B552583/awarecon?serviceKey={service_key_encoded}&pageNo={page_no}&numOfRows={num_of_rows}&type={response_type}"

# 3ï¸âƒ£ API ìš”ì²­
try:
    response = requests.get(url)
    if response.status_code != 200:
        st.error(f"âš ï¸ API ìš”ì²­ ì‹¤íŒ¨: HTTP {response.status_code}")
        st.stop()
except Exception as e:
    st.error(f"âš ï¸ API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()

# 4ï¸âƒ£ XML íŒŒì‹±
try:
    root = ET.fromstring(response.content)
    items = root.findall(".//item")
    data = []
    for r in items:
        row_dict = {
            "êµìœ¡ê¸°ê´€ëª…": r.findtext("INSTT_NM", default=""),
            "êµìœ¡ëª…": r.findtext("EDU_NM", default=""),
            "êµìœ¡ë‚´ìš©": r.findtext("EDU_CN", default=""),
            "ì£¼ì†Œ": r.findtext("EDU_ADDR", default=""),
            "ë‹´ë‹¹ì": r.findtext("EDU_RPRSNTV_NM", default=""),
            "ì—°ë½ì²˜": r.findtext("EDU_TELNO", default=""),
        }
        data.append(row_dict)
except Exception as e:
    st.error(f"âš ï¸ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()

df = pd.DataFrame(data)

if df.empty:
    st.warning("âš ï¸ APIì—ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# 5ï¸âƒ£ ì „ì²´ ë°ì´í„° í‘œì‹œ
st.dataframe(df, use_container_width=True)
